{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of representations in hidden layers\n",
    "\n",
    "Now we start looking at representations in hidden layers of\n",
    "a trained network\n",
    "\n",
    "# Guided exercise\n",
    "\n",
    "First of all we have to open \n",
    "\n",
    "    mnist_cnn.py \n",
    "\n",
    "and\n",
    "\n",
    "- familiarize with the code\n",
    "- launch the script to train it and save the model in \n",
    "      \n",
    "        mnist_cnn.pt\n",
    "       \n",
    "using command  `python3 mnist_cnn.py --save-model`\n",
    "\n",
    "Then we will go back to this notebook and\n",
    "\n",
    "- load the model (see also\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "- extract and visualize representations with T-SNE\n",
    "\n",
    "We will not explain T-SNE but you will find the following resources\n",
    "\n",
    "- the documentation on scikit-learn\n",
    "  https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "\n",
    "- the original paper        http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf \n",
    "  (also in the bibliography)\n",
    "\n",
    "- the *distill* article (which is a wonderful source of information on networks)\n",
    "  https://distill.pub/2016/misread-tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same network as in the script\n",
    "\n",
    "    mnist_cnn.py\n",
    "    \n",
    "Usually you may want to put this in a module, anyway I reproduce it\n",
    "here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    #define the building blocks that i need:\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #convolutional layers for 1 channel, 20 filters of size 5x5:\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1) # keep last parameter =1\n",
    "        \n",
    "        #another convolutional layer with an input of 20 channels \n",
    "        #(20 versions of the image given by the 20 filter)\n",
    "        # this convolutiona layer has 50 filters of size 5x5:\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        \n",
    "        # 500 is the width of the last hidden layer\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        # transformation from the size of the last\n",
    "        # hidden layer to the output\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    # describe the flow of information inside the network:\n",
    "    def forward(self, x):\n",
    "        # do a convulution and apply the relu :\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # take the max value of the maps  reducing the \n",
    "        # representation by a factor of 2x2=4 :\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        # again, do a convulution and apply the relu :\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # further reducing the dimensionality of the reppresentation :\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        # for each datapoint a want one vector of length 4*4*50 :\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        # flatten it into a single vector : \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # perform the last linear transformation applying the last\n",
    "        # non-linearity :\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "input_size=(1,28,28,) # Notice that now the input is not unrolled like in the MLP\n",
    "batch_size=64\n",
    "test_batch_size=1000\n",
    "epochs=1\n",
    "lr=0.01\n",
    "momentum=0.0   \n",
    "seed=1\n",
    "log_interval=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 20, 24, 24]             520\n",
      "            Conv2d-2             [-1, 50, 8, 8]          25,050\n",
      "            Linear-3                  [-1, 500]         400,500\n",
      "            Linear-4                   [-1, 10]           5,010\n",
      "================================================================\n",
      "Total params: 431,080\n",
      "Trainable params: 431,080\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 1.64\n",
      "Estimated Total Size (MB): 1.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model's state_dict:\n",
      "conv1.weight \t torch.Size([20, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([20])\n",
      "conv2.weight \t torch.Size([50, 20, 5, 5])\n",
      "conv2.bias \t torch.Size([50])\n",
      "fc1.weight \t torch.Size([500, 800])\n",
      "fc1.bias \t torch.Size([500])\n",
      "fc2.weight \t torch.Size([10, 500])\n",
      "fc2.bias \t torch.Size([10])\n",
      "\n",
      "optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0.0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140182433811336, 140182433811480, 140182433811408, 140182433811768, 140182433811912, 140182433811840, 140182433811984, 140182433811696]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"model's state_dict:\")\n",
    "for p in model.state_dict():\n",
    "    print(p, \"\\t\", model.state_dict()[p].size())\n",
    "\n",
    "\n",
    "print(\"\\noptimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#optimizer.state_dict??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optimizer.step` re-computes $\\theta=\\theta - \\alpha $ $<$grad L$>$. Where $<.>$ is an exponentially weighted average.\n",
    "\n",
    "When adding momentum through `data, target = data.to(device), target.to(device)`\n",
    "\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True\n",
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 True\n",
      "6 True\n",
      "7 True\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(model.parameters()):\n",
    "    print(i, p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to freeze the first layers as we'll do in the transfert learning exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0272, -0.0286, -0.0184,  0.0234, -0.0131,  0.0106, -0.0341, -0.0158,\n",
      "        -0.0351,  0.0106], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[4][0,0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('mnist_cnn.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.parameters())[4][0,0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the trained model back we extract its representations, but how can we do that?\n",
    "Think about that for a minute before going on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,labels = next(iter(test_loader))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(inputs).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output[0,:],'-o')\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representations extraction\n",
    "\n",
    "Define a new class identical to Net but with a method to extract activation in\n",
    "the following places:\n",
    "\n",
    "- after the first ReLU        **(h1)**\n",
    "- after the first pooling     **(h2)**\n",
    "- after the second ReLU       **(h3)**\n",
    "- after the second pooling    **(h4)**\n",
    "- after the third ReLU        **(h5)**\n",
    "- at output                   **(h6)**\n",
    "\n",
    "Then extract all these activations in correspondance with the input\n",
    "forward pass and analyze them with T-SNE \n",
    "(including the input in the analysis for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def extract(self,x):\n",
    "        ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
